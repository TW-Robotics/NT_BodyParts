# The train_model.py script implements the VGG16 model creation,
# model training and model evaluation. Data augmentation can be
# activated and deactivated. This script access the image data generated 
# by the CNN.py script. Those images are used for training and 
# evaluation.
# Afterwards, the models are evaluated using the test images. Visualization
# maps are generated and stored for (i) the elements with highest
# class probability and (ii) all other. Faulty classified images
# are marked with a 'F' in the file name.
#
# This code is available under a GPL v3.0 license and comes without
# any explicit or implicit warranty.
#
# (C) Wilfried Woeber 2020 <wilfried.woeber@technikum-wien.at>
from keras.applications import VGG16    #Import the VGG capabilities
from keras import models                #Import models --> several layers
from keras import layers                #Layers :-)
from keras import optimizers            #Keras optimizer
from keras.preprocessing.image import ImageDataGenerator        #Data generator for augmention
from keras.layers import Input, Flatten, Dense, Dropout
from keras.models import Model
from sklearn.metrics import confusion_matrix        #Confusion matrix
import sys 
import numpy as np
#------------------------------#
#--- Define global settings ---#
#------------------------------#
train_dir="./train"         #Train folder generated by bash script
validation_dir="./test"     #Test folder generated by test script
image_size=224              #Image size of VGG
train_batchsize = 8         #Used batches for training
val_batchsize = 5           #Validation batchsize
Augmention=bool(sys.argv[1])    #Get augmention flag
print("Augmention:", Augmention)
#--------------------------#
#--- Load the VGG model ---#
#--------------------------#
vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))
#--- Freeze the layers except the last 4 layers ---#
for layer in vgg_conv.layers[:-4]:
    layer.trainable = False
#--- Check the trainable status of the individual layers ---#
#for layer in vgg_conv.layers:
#    print(layer, layer.trainable)
#------------------------#
#--- Create the model ---#
#------------------------#
#--- We have to do this cuz of Keras-viz ---#
last = vgg_conv.output
x = Flatten()(last)
x= Dense(1024,activation='relu')(x)
x=Dropout(0.5)(x)
pred=Dense(6,activation='softmax')(x)
model = Model(vgg_conv.input,pred)
#---  Show a summary of the model ---#
model.summary()
#-----------------------------------#
#--- Define trainign environment ---#
#-----------------------------------#
#--- Image data generators ---#
if(Augmention):
    train_datagen = ImageDataGenerator(                     #Augmention
        rescale=1./255,
          rotation_range=20,
          width_shift_range=0.2,
          height_shift_range=0.2,
          horizontal_flip=True,
          fill_mode='nearest')
else:
    train_datagen = ImageDataGenerator(rescale=1./255)     #No augmention
validation_datagen = ImageDataGenerator(rescale=1./255)
#--- Get generators ---#
train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(image_size, image_size),
        batch_size=train_batchsize,
        class_mode='categorical')
validation_generator = validation_datagen.flow_from_directory(
        validation_dir,
        target_size=(image_size, image_size),
        batch_size=val_batchsize,
        class_mode='categorical',
        shuffle=False)
#-------------------#
#--- Train model ---#
#-------------------#
model.compile(loss='categorical_crossentropy',
              optimizer=optimizers.RMSprop(lr=1e-4),
              metrics=['acc'])
history = model.fit_generator(
      train_generator,
      steps_per_epoch=train_generator.samples/train_generator.batch_size ,
      epochs=70,
      validation_data=validation_generator,
      validation_steps=validation_generator.samples/validation_generator.batch_size,
      verbose=1)
#-------------------#
#--- Store model ---#
#-------------------#
#model.save('my_fish_model.h5')
print('Accuracy_fin:',history.history['val_acc'][-1])   #Print accuracy
#------------------#
#--- Test model ---#
#------------------#
train_im = ImageDataGenerator(rescale=1./255)
def test_images():
    train_generator = train_im.flow_from_directory (
            validation_dir, 
            target_size=(224, 224),
            color_mode='rgb',
            batch_size=104,
            shuffle = True,
            class_mode='categorical'
         )
    x =  train_generator
    return x[0][0], x[0][1]
test_data = test_images()
#--- Do predcition ---#
#prediction = model.predict(test_data[0])
#prediction_row = np.argmax(prediction,1)
#groundTruth_row = np.argmax(test_data[1],1)
#CM = confusion_matrix(prediction_row, groundTruth_row)
#print(CM)
#np.savetxt("CM.csv", CM)
#np.savetxt("loss.csv", history.history['loss'])
#-----------------#
#--- Keras VIS ---#
#-----------------#
#------------------------#
#--- Do vizualization ---#
#------------------------#
from vis.utils import utils
from keras import activations
#--- Find prediction layer and replace it ---#
layer_idx = -1 #utils.find_layer_idx(model, 'predictions')
model.layers[layer_idx].activation = activations.linear
model = utils.apply_modifications(model)
#------------------------#
#--- Load fish images ---#
#------------------------#
from vis.utils import utils
import matplotlib.pyplot as plt
import numpy as np
import matplotlib.cm as cm
from vis.visualization import visualize_cam, overlay
import innvestigate
import innvestigate.utils as iutils
model_wo_softmax = model
LPR_10 = innvestigate.analyzer.relevance_based.relevance_analyzer.LRPAlphaBeta(model_wo_softmax,1,0)

layer_idx = -1
Class_Names = np.array(('Chamo', 'Hawassa','Koka', 'Lan', 'Tana', 'Ziway'))
prediction = model.predict(test_data[0])
ground_truth = test_data[1]
for i in range(0,len(Class_Names)):
    print("Class: %s"% Class_Names[i])
    pred_row = prediction[:,i]
    index = np.argmax(pred_row)
    if( ground_truth[index,i] != 1):
        print("oi...")
    else:
        print("yes")
    grads = visualize_cam(model, layer_idx, filter_indices=train_generator.class_indices[Class_Names[i]], seed_input=test_data[0][index], backprop_modifier='guided')
    LRP_10_i    = LPR_10.analyze(test_data[0][index].reshape((1,224,224,3)))

    plt.imshow(grads)
    plt.axis('off')
    plt.savefig(Class_Names[i]+"_grad.pdf",dpi=1200)
    plt.close('all')
    plt.imshow(LRP_10_i[0,:,:,0])
    plt.axis('off')
    plt.savefig(Class_Names[i]+"_LRP_10.pdf",dpi=1200)
    plt.close('all')
    plt.imshow(test_data[0][index])
    plt.axis('off')
    plt.savefig(Class_Names[i]+".pdf",dpi=1200)
    plt.close('all')
#-------------------#
#--- All of them ---#
#-------------------#
for i in range(0,prediction.shape[0]):
    print("Iteration: ", i)
    pred_row = prediction[i,:]
    index = np.argmax(pred_row)
    prefix=""
    if( ground_truth[i,index] != 1):
        print("Something went wrong")
        prefix="F_"
    else:
        print("yes")
    grads = visualize_cam(model, layer_idx, filter_indices=train_generator.class_indices[Class_Names[np.argmax(ground_truth[i,:])]], seed_input=test_data[0][i], backprop_modifier='guided')
    LRP_10_i    = LPR_10.analyze(test_data[0][i].reshape((1,224,224,3)))
    #LRP_21_i    = LPR_21.analyze(test_data[0][i].reshape((1,224,224,3)))

    plt.imshow(grads)
    plt.axis('off')
    plt.savefig(str(i)+'_'+prefix+Class_Names[np.argmax(ground_truth[i,:])]+"_grad.pdf",dpi=1200)
    plt.close('all')
    plt.imshow(LRP_10_i[0,:,:,0])
    plt.axis('off')
    plt.savefig(str(i)+'_'+prefix+Class_Names[np.argmax(ground_truth[i,:])]+"_LRP_10.pdf",dpi=1200)
    plt.close('all')
    plt.imshow(test_data[0][i])
    plt.axis('off')
    plt.savefig(str(i)+'_'+prefix+Class_Names[np.argmax(ground_truth[i,:])]+".pdf",dpi=1200)
    plt.close('all')
