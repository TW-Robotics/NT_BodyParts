# The CNN.py script creates the training and test data for the CNN
# classification. After all images were created, the CNN training
# script is called.
# To allow statistical analysis afterwards, the speciment must appear
# exaclty in the same order as for GPC. Thus, the BGPLVM training data
# matrix is used to  get the speciment IDs. Based on those IDs, the 
# train and test folders for the CNN is created. Afterwards, the train_model.py
# script is called.
# All files generated by the CNN trainign are deleted after data analysis. If
# detailed analysis is wanted, the line 'os.system("rm *.csv")' can be removed.
# All relevant training/test results are stored in the X_dataMatrix.csv files,
# where X is 0..9 (for each iteration).
#
# This code is available under a GPL v3.0 license and comes without
# any explicit or implicit warranty.
#
# (C) Wilfried Woeber 2020 <wilfried.woeber@technikum-wien.at>
#-------------------------#
#--- Run main programm ---#
#-------------------------#
import numpy as np                      #Numpy ;)
import pandas as pd                     #We need that for novel data loading
import os                               #Folder handling for training data creation
import shutil                           #Recursivly folder delete, copy files
#import io
import sys
#-------------------------------#
#--- Some global definitions ---#
#-------------------------------#
Augmention=sys.argv[1]=="1"            #Get augmention flag
print("Augmentation:", Augmention)
n_fold=10                               #k for k-fold cross validation
path_images = "../../Data/images/"      #Path to images
if(Augmention):
    os.system("mkdir Augmented")
else:
    os.system("mkdir notAugmented")
#-----------------------------#
#--- Some global functions ---#
#-----------------------------#
#Removing existing folders
def rm_dirs():
    #-----------------------#
    #--- RM train folder ---#
    #-----------------------#
    if(os.path.isdir("./train")):
        print("rm train folder...")
        shutil.rmtree(os.path.abspath(os.getcwd())+"/train")
    if(os.path.isdir("./test")):
        print("rm test folder...")
        shutil.rmtree(os.path.abspath(os.getcwd())+"/test")
#Create class folders
def create_class(file_path,CLASS):
    try:
        os.mkdir(file_path)
    except OSError:
        print ("Cannot create folder %s" % file_path)
    else:
        print ("Created folder %s" % file_path)
    for CLASS in class_names:
        try:
            os.mkdir(file_path+CLASS)
        except OSError:
            print ("Cannot create train folder for %s" % file_path+CLASS)
        else:
            print ("Created train folder for %s " % file_path+CLASS)
#Move images to folders
def moveImages(IDs,folder,labels):
    #print("Move %d images" % IDs.shape[0])
    looper=0    #Looper for labels
    for ID in IDs:
        #print("Move %s to %s" % (ID,folder))
        #--- Check if its copy ---#
        prefix=""
        while(True):
            copy_path = folder+class_names[labels[looper]]+"/"+prefix+ID+".jpg"
            if(os.path.isfile(copy_path)):
                prefix=prefix+"copy_"
            else:
                #shutil.copy2(path_images+ID+".jpg", folder+class_names[labels[looper]]+"/"+ID+".jpg")   #Copy file to folder
                shutil.copy2(path_images+ID+".jpg", copy_path)   #Copy file to folder
                looper=looper+1
                break
#Convert CNN result in our format again
def convertData(CNNDataMatrix, ID_test):
    data_fin = np.ones((CNNDataMatrix.shape[0],1))*(-1)
    #--- Loop over all test IDs ---#
    looper=0
    for testID in ID_test:
        ID=-1
        #--- Find right row and store indices ---#
        #print("Check for %s" % testID)
        for i in range(0,CNNDataMatrix.shape[0]):   #Loop over all CNN test cases
            #print("Check %s" % CNNDataMatrix[i,0])
            matchedID = CNNDataMatrix[i,0].find(testID)
            if(matchedID >= 0):
                ID=i
                break
        #print("Match @ %d" % ID)
        data_fin[looper,:] = ID
        looper=looper+1
    return data_fin.astype(int) #Return indices for correction
#--------------------------------------#
#--- Load files from data generator ---#
#--------------------------------------#
class_names = np.genfromtxt("../../Data/classes.csv", dtype=str)                #Names of fishes
data_file = pd.read_csv('../../GPLVM/BGPLVM_DATA.csv', header=None).as_matrix() #Read data including sample ID
# The format is for each row: sampleID (string), label (int), data vector (double)
samples_iteration  = np.genfromtxt("../../Data/NoReplace_20205809_085859.csv", 
                                    delimiter=' ',dtype=int)                    #Load data from R script
#-------------------#
#--- Create data ---#
#-------------------#
sample_ID = data_file[:,0]                      #The sample ID
labels_raw = data_file[:,1]                     #Stored labels
data_raw = data_file[:,1:data_file.shape[1]]    #The label followed by data (BGPLVM features)
#------------------#
#--- Do looping ---#
#------------------#
for ITERATION in range (0,samples_iteration.shape[1]):
    #-----------------------#
    #--- Get specimen ID ---#
    #-----------------------#
    IDs = sample_ID[samples_iteration[:,ITERATION]]     #Get IDs for image filename generation
    labels = labels_raw[samples_iteration[:,ITERATION]] #Get randomized labels
    #-------------------------------#
    #--- k-fold cross validation ---#
    #-------------------------------#
    fold_iterator = np.ceil(float(IDs.shape[0])/float(n_fold))     #We get the index iteration number here
    data_memory = np.array(())
    data_memory_test = np.array(())
    test=np.array(range(0,209))
    for k in range(0,n_fold):
        #-------------------------------------#
        #--- Create train and test folders ---#
        #-------------------------------------#
        rm_dirs()                               #Remove existing folder
        create_class("./train/", class_names)   #Create train folders
        create_class("./test/", class_names)    #Create test folders
        #sys.stdout = sys.__stdout__
        #--- get sample names ---#
        index_start = int(k*fold_iterator)          #Get start point
        index_end = int(index_start+fold_iterator)  #Increment using theoretical sampling
        print("Indices %d - %d " % (index_start , index_end))
        if(index_end > (IDs.shape[0]-1)):           #Check if everything is fine
            index_end = IDs.shape[0]                #In case of my bad math
            print("Indices %d - %d " % (index_start , index_end))
        #--- Build sampel IDs ---#
        ID_train    = np.delete(IDs,range(index_start,index_end),0)
        ID_test     = IDs[index_start:index_end]
        labels_train= np.delete(labels,range(index_start,index_end),0)
        labels_test = labels[index_start:index_end]
        #--- Move images ---#
        moveImages(ID_train,"./train/", labels_train)  #Move to train folder
        moveImages(ID_test,"./test/", labels_test)     #Move to test folder
        #---------------#
        #--- Run CNN ---#
        #---------------#
        if(Augmention):
            os.system("../../Python/VE_CNN/bin/python trainModel.py 1 > logfile_"+str(ITERATION)+"_"+str(k)+"_.log")
        else:
            os.system("../../Python/VE_CNN/bin/python trainModel.py 0 > logfile_"+str(ITERATION)+"_"+str(k)+"_.log")
        #-----------------------------------#
        #--- Load data from CNN training ---#
        #-----------------------------------#
        os.system("mv CNNmodel CNNmodel_"+str(ITERATION)+"_"+str(k))
        os.system("mv train train_"+str(ITERATION)+"_"+str(k))
        os.system("mv test test_"+str(ITERATION)+"_"+str(k))
        os.system("mv *.pdf test_"+str(ITERATION)+"_"+str(k))
        os.system("mv *.npy test_"+str(ITERATION)+"_"+str(k))

        run_pred_labels     = np.genfromtxt("./label_prediction.csv", delimiter=' ').astype(int)
        run_groundT_labels  = np.genfromtxt("./label_groundTruth.csv", delimiter=' ').astype(int)
        run_file_names      = np.genfromtxt("./label_IDs.csv", delimiter=' ', dtype=str)
        run_pred_probs      = np.genfromtxt("./label_predProb.csv", delimiter=' ')
        data_iteration_RAW  = np.concatenate(    (run_file_names.reshape((labels_test.shape[0],1)), #Sample name
                                            run_groundT_labels.reshape((labels_test.shape[0],1)),   #True class
                                            run_pred_labels.reshape((labels_test.shape[0],1)),      #Predicted class
                                            run_pred_probs),                                        #Class probability
                                        axis=1) #Create data matrix
        indices_convert     = convertData(data_iteration_RAW,ID_test)   #Get indices to correct order (CNN mixes...)
        data_iteration      = data_iteration_RAW[indices_convert,:].reshape((ID_test.shape[0],9))   #Correct data
        #--- Store results ---#
        if(data_memory.shape[0] == 0): #initial memory
            data_memory = data_iteration
            data_memory_test = test[index_start:index_end]
        else:
            data_memory = np.concatenate((data_memory,data_iteration),axis=0)
            data_memory_test = np.concatenate((data_memory_test,test[index_start:index_end]),axis=0)
        #--------------------------------------#
        #--- Clear up before next iteration ---#
        #--------------------------------------#
        os.system("mv *.csv train_"+str(ITERATION)+"_"+str(k))
        #os.system("rm label*")   #We do not need the CSV files anymore
    #-------------------------------------------------#
    #--- Convert data frame to project data format ---#
    #-------------------------------------------------#
    data_list = {   "ttarg":data_memory[:,1].reshape((209,)), 
                    "ptarg":data_memory[:,2].reshape((209,)), 
                    "probs0":data_memory[:,3].reshape((209,)),
                    "probs1":data_memory[:,4].reshape((209,)),
                    "probs2":data_memory[:,5].reshape((209,)),
                    "probs3":data_memory[:,6].reshape((209,)),
                    "probs4":data_memory[:,7].reshape((209,)),
                    "probs5":data_memory[:,8].reshape((209,))}
    df = pd.DataFrame(data=data_list)
    df = df[["ttarg", "ptarg", "probs0", "probs1", "probs2", "probs3", "probs4", "probs5"]]
    #df = pd.DataFrame(data=data_memory)
    prefix = str(ITERATION)
    df.to_csv(prefix+"_dataMatrix.csv", index=False)
    if(Augmention):
        os.system("mv *_dataMatrix.csv Augmented/.")
    else:
        os.system("mv *_dataMatrix.csv notAugmented/.")
#-----------------#
#--- Move data ---#
#-----------------#
if(Augmention):
    os.system("mv train_* Augmented/.")
    os.system("mv test_* Augmented/.")
    os.system("mv CNNmodel* Augmented/.")
    os.system("mv *.log Augmented/.")
else:
    os.system("mv train_* notAugmented/.")
    os.system("mv test_* notAugmented/.")
    os.system("mv CNNmodel* notAugmented/.")
    os.system("mv *.log notAugmented/.")
