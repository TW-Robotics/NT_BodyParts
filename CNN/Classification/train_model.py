# The train_model.py script implements the VGG16 model creation,
# model training and model evaluation. Data augmentation is set
# to true (default). This script access the image data generated 
# by the CNN.py script. Those images are used for training and 
# evaluation.
# After the model was tested, the results are stored in CSV files
# and analysed afterwards.
#
# This code is available under a GPL v3.0 license and comes without
# any explicit or implicit warranty.
#
# (C) Wilfried Woeber 2020 <wilfried.woeber@technikum-wien.at>
from keras.applications import VGG16    #Import the VGG capabilities
from keras import models                #Import models --> several layers
from keras import layers                #Layers :-)
from keras import optimizers            #Keras optimizer
from keras.preprocessing.image import ImageDataGenerator        #Data generator for augmention
from sklearn.metrics import confusion_matrix        #Confusion matrix
import sys 
import numpy as np
#------------------------------#
#--- Define global settings ---#
#------------------------------#
train_dir="./train"         #Train folder generated by bash script
validation_dir="./test"     #Test folder generated by test script
image_size=224              #Image size of VGG
train_batchsize = 8         #Used batches for training
val_batchsize = 5           #Validation batchsize
Augmention=True             #Set augmention flag
print("Augmention:", Augmention)
#--------------------------#
#--- Load the VGG model ---#
#--------------------------#
vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))
#--- Freeze the layers except the last 4 layers ---#
for layer in vgg_conv.layers[:-4]:
    layer.trainable = False
#--- Check the trainable status of the individual layers ---#
for layer in vgg_conv.layers:
    print(layer, layer.trainable)
#------------------------#
#--- Create the model ---#
#------------------------#
model = models.Sequential()     #Naked model for fintuned VGG
model.add(vgg_conv)             #Add VGG backbone
#--- Add new layers ---#
model.add(layers.Flatten())                         #Flatten after conv layers 
model.add(layers.Dense(1024, activation='relu'))    #A dense layer with 1024 neurons (from example)
model.add(layers.Dropout(0.5))                      #Dropout decrease overfit
#model.add(layers.Dense(85, activation='softmax'))
model.add(layers.Dense(6, activation='softmax'))   #Softmax - one for each output class
#---  Show a summary of the model ---#
model.summary()
#-----------------------------------#
#--- Define trainign environment ---#
#-----------------------------------#
#--- Image data generators ---#
if(Augmention):
    train_datagen = ImageDataGenerator(                     #Augmention
        rescale=1./255,
          rotation_range=20,
          width_shift_range=0.2,
          height_shift_range=0.2,
          horizontal_flip=True,
          fill_mode='nearest')
else:
    train_datagen = ImageDataGenerator(rescale=1./255)     #No augmention
validation_datagen = ImageDataGenerator(rescale=1./255)
#--- Get generators ---#
train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(image_size, image_size),
        batch_size=train_batchsize,
        class_mode='categorical')
validation_generator = validation_datagen.flow_from_directory(
        validation_dir,
        target_size=(image_size, image_size),
        batch_size=val_batchsize,
        class_mode='categorical',
        shuffle=False)
#-------------------#
#--- Train model ---#
#-------------------#
model.compile(loss='categorical_crossentropy',
              optimizer=optimizers.RMSprop(lr=1e-4),
              metrics=['acc'])
history = model.fit_generator(
      train_generator,
      steps_per_epoch=train_generator.samples/train_generator.batch_size ,
      epochs=70,
      validation_data=validation_generator,
      validation_steps=validation_generator.samples/validation_generator.batch_size,
      verbose=1)
#-------------------#
#--- Store model ---#
#-------------------#
print('Accuracy_fin:',history.history['val_acc'][-1])   #Print accuracy
#------------------#
#--- Test model ---#
#------------------#
train_im = ImageDataGenerator(rescale=1./255)
def test_images():
    train_generator = train_im.flow_from_directory (
            validation_dir, 
            target_size=(224, 224),
            color_mode='rgb',
            batch_size=104,
            shuffle = False,
            class_mode='categorical'
         )
    x =  train_generator
    return x[0][0], x[0][1], train_generator.filenames
test_data = test_images()
#--- Do predcition ---#
prediction = model.predict(test_data[0])
prediction_row = np.argmax(prediction,1)
groundTruth_row = np.argmax(test_data[1],1)
CM = confusion_matrix(prediction_row, groundTruth_row)
print(CM)
#-------------------#
#--- Store stuff ---#
#-------------------#
np.savetxt("CM.csv", CM)
np.savetxt("loss.csv", history.history['loss'])
np.savetxt("label_prediction.csv", prediction_row)
np.savetxt("label_groundTruth.csv", groundTruth_row)
np.savetxt("label_IDs.csv", test_data[2], fmt="%s")
np.savetxt("label_predProb.csv", prediction)
#np.savetxt(
